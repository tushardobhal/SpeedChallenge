{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Optical Flow Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('test.mp4')\n",
    "ret, frame1 = cap.read()\n",
    "prv = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "\n",
    "indx = 2\n",
    "while(True):\n",
    "    ret, frame2 = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    nxt = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(prv, nxt, None, 0.5, 3, 15, 3, 5, 1.1, 1)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.imwrite('testflow2/'+str(indx)+'.jpg', bgr)\n",
    "    prv = nxt;\n",
    "#     cv2.imshow(\"flow\", bgr)\n",
    "    \n",
    "    indx = indx + 1\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "    \tbreak\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "nc = 3\n",
    "ngf = 64\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_path = 'flow/'\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "num_images = 16319\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader class which outputs a batch of (Images, Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = data_path\n",
    "        imgs = os.listdir(self.data_path)\n",
    "        imgs = sorted(imgs, key=lambda x: int(os.path.splitext(x)[0]))\n",
    "        lbls = pd.read_csv('train.txt', sep=\" \", header=None)\n",
    "        lbls = lbls[lbls.columns[0]][1:].tolist()\n",
    "        self.train_images, self.test_images, self.train_lbls, self.test_lbls = train_test_split(imgs,lbls, \n",
    "                                                                        test_size=0.2, random_state=42)\n",
    "        self.data_transforms = torchvision.transforms.Compose([\n",
    "#                 torchvision.transforms.Resize([224, 224]), \n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "        \n",
    "    def load_img(self, image_name):\n",
    "        image = Image.open(image_name)\n",
    "        image = self.data_transforms(image).float()\n",
    "        image = torch.autograd.Variable(image, requires_grad=False)\n",
    "        image = image.unsqueeze(0)\n",
    "        return image.to(device)\n",
    "    \n",
    "    def get_data(self, train=True):\n",
    "        if train == True:\n",
    "            images = self.train_images\n",
    "            lb = self.train_lbls\n",
    "        else:\n",
    "            images = self.test_images\n",
    "            lb = self.test_lbls\n",
    "        \n",
    "        while True:\n",
    "            ix = np.random.choice(np.arange(len(images)), self.batch_size)\n",
    "            x = []\n",
    "            y = []\n",
    "            for i in ix:\n",
    "                x.append(self.load_img(self.data_path + images[i]))\n",
    "                y.append(torch.tensor((lb[i])))\n",
    "            yield torch.stack(x), torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network used for Prediction from Optical Flow images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(network, self).__init__()\n",
    "        \n",
    "        # 480 x 640\n",
    "        self.conv1 = nn.Conv2d(nc, ngf, 4, 2, 1, bias=True)\n",
    "        self.r1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 240 x 320\n",
    "        self.conv2 = nn.Conv2d(ngf, ngf*2, 4, 2, 1, bias=True)\n",
    "        self.in2 = nn.InstanceNorm2d(ngf*2)\n",
    "        self.r2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 120 x 160\n",
    "        self.conv3 = nn.Conv2d(ngf*2, ngf*4, 4, 2, 1, bias=True)\n",
    "        self.in3 = nn.InstanceNorm2d(ngf*4)\n",
    "        self.r3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 60 x 80\n",
    "        self.conv4 = nn.Conv2d(ngf*4, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.in4 = nn.InstanceNorm2d(ngf*8)\n",
    "        self.r4 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 30 x 40\n",
    "        self.conv5 = nn.Conv2d(ngf*8, ngf*16, 4, 2, 1, bias=True)\n",
    "        self.in5 = nn.InstanceNorm2d(ngf*16)\n",
    "        self.r5 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 15 x 20\n",
    "        self.conv6 = nn.Conv2d(ngf*16, ngf*8, 1, 1, 0, bias=True)\n",
    "        self.in6 = nn.InstanceNorm2d(ngf*8)\n",
    "        self.r6 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(ngf*8, ngf*4, 1, 1, 0, bias=True)\n",
    "        self.in7 = nn.InstanceNorm2d(ngf*4)\n",
    "        self.r7 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(ngf*4, ngf*2, 1, 1, 0, bias=True)\n",
    "        self.in8 = nn.InstanceNorm2d(ngf*2)\n",
    "        self.r8 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(ngf*2, ngf, 1, 1, 0, bias=True)\n",
    "        self.in9 = nn.InstanceNorm2d(ngf)\n",
    "        self.r9 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(ngf, 3, 1, 1, 0, bias=True)\n",
    "        self.in10 = nn.InstanceNorm2d(ngf/64)\n",
    "        self.r10 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.lin11 = nn.Linear(15*20*3, 100)\n",
    "        \n",
    "        self.lin12 = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        c2 = self.in2(self.conv2(self.r1(c1)))\n",
    "        c3 = self.in3(self.conv3(self.r2(c2)))\n",
    "        c4 = self.in4(self.conv4(self.r3(c3)))\n",
    "        c5 = self.in5(self.conv5(self.r4(c4)))\n",
    "        c6 = self.in6(self.conv6(self.r5(c5)))\n",
    "        c7 = self.in7(self.conv7(self.r6(c6)))\n",
    "        c8 = self.in8(self.conv8(self.r7(c7)))\n",
    "        c9 = self.in9(self.conv9(self.r8(c8)))\n",
    "        c10 = self.in10(self.conv10(self.r9(c9)))\n",
    "        l11 = self.lin11(self.r10(c10.view(c10.size()[0], -1)))\n",
    "        l12 = self.lin12(l11)\n",
    "        \n",
    "        return l12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = network().to(device)\n",
    "net.apply(weights_init_normal)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim_net = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_interval = 10\n",
    "checkpoint_interval = 500\n",
    "file_name = 'train/net.pth'\n",
    "if os.path.isfile(file_name):\n",
    "    net.load_state_dict(torch.load(file_name))\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "    for i in range(num_images // batch_size):\n",
    "        x, y = next(loader.get_data(True))\n",
    "        real_x = torch.autograd.Variable(x).to(device)\n",
    "        real_y = torch.autograd.Variable(y).to(device)\n",
    "        \n",
    "        optim_net.zero_grad();\n",
    "        pred = net(real_x).view(-1)\n",
    "        loss = criterion(pred, real_y)\n",
    "        loss.backward()\n",
    "        optim_net.step()\n",
    "        \n",
    "        if i % print_interval == 0: \n",
    "            print(\"\\r[Epoch %d/%d] [Batch %d/%d] [Train_loss: %f]\" %\n",
    "                                                    (epoch, num_epochs, i, num_images//batch_size, loss))\n",
    "        if i % checkpoint_interval == 0:\n",
    "            v_loss = validate()\n",
    "            print(\"\\r[Epoch %d/%d] [Batch %d/%d] [Train_loss: %f] [Validation_loss: %f]\" %\n",
    "                                                    (epoch, num_epochs, i, num_images//batch_size, loss, v_loss))\n",
    "            torch.save(net.state_dict(), file_name)     \n",
    "        \n",
    "    torch.save(net.state_dict(), \"train/net_{}.pth\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation for Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate():\n",
    "    x, y = next(loader.get_data(False))\n",
    "    real_x = torch.autograd.Variable(x).to(device)\n",
    "    real_y = torch.autograd.Variable(y).to(device)\n",
    "    \n",
    "    pred = net(real_x).view(-1)\n",
    "    loss = criterion(pred, real_y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load optical flow for test video and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_video():\n",
    "    net.load_state_dict(torch.load(\"train/custom_net/net_10.pth\"))\n",
    "    out = cv2.VideoWriter('speed.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 20, (640, 480))\n",
    "    for i in range(2, 20400):\n",
    "        im = cv2.imread(\"frames/{}.jpg\".format(i))\n",
    "        flow = loader.load_img(\"flow/{}.jpg\".format(i))\n",
    "        real_x = torch.autograd.Variable(flow).to(device)\n",
    "        pred = net(real_x).view(-1)\n",
    "        frame = cv2.putText(im, \"{}\".format(pred.item()), org=(20,20), fontFace=3, fontScale=.5, color=(255, 255, 255), thickness=1)\n",
    "        cv2.imshow('frame', frame)\n",
    "        out.write(frame)\n",
    "    \n",
    "    cv2.destroyAllWindows()    \n",
    "    out.release()\n",
    "    \n",
    "test_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
